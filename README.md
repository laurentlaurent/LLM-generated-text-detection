# Fast-DetectGPT

An implementation of the Fast-DetectGPT algorithm for detecting AI-generated text. This project reproduces the results of the original Fast-DetectGPT algorithm on multiple datasets.

## Overview

Fast-DetectGPT is a lightweight and efficient method for detecting text generated by large language models. This implementation uses conditional probability curvature to distinguish between human and AI-generated text, requiring only black-box access to the language model.

## References

This work is based on the following paper:
- **Fast-DetectGPT: Efficient Zero-Shot Detection of Machine-Generated Text via Conditional Probability Curvature**

The original code repository is available on GitHub:
- [https://github.com/baoguangsheng/fast-detect-gpt](https://github.com/baoguangsheng/fast-detect-gpt)

## Datasets

The implementation is tested on three datasets:
- **XSum**: News article summarization dataset
- **SQuAD**: Stanford Question Answering Dataset
- **PubMedQA**: Medical question answering dataset

## Methodology

The detection approach follows Algorithm 1 from the Fast-DetectGPT paper:
1. Generate perturbed samples by conditional sampling
2. Calculate log probabilities of the samples
3. Compute mean and standard deviation of these log probabilities
4. Calculate the log probability of the original text
5. Compute the normalized curvature score as (original_log_prob - mean) / std_dev

The higher the curvature score, the more likely the text is AI-generated.

## Results

Detection performance across datasets:

| Dataset | ROC AUC | PR AUC | Best F1 | Accuracy | Precision | Recall |
|---------|---------|--------|---------|----------|-----------|--------|
| XSum    | 0.7320  | 0.7071 | 0.7667  | 0.7200   | 0.6571    | 0.9200 |
| SQuAD   | 0.6223  | 0.6373 | 0.7073  | 0.6129   | 0.5686    | 0.9355 |
| PubMedQA| 0.7916  | 0.7474 | 0.7797  | 0.7400   | 0.6765    | 0.9200 |

## Visualizations

The repository includes several visualization outputs:
- Confusion matrices (`confusion_matrix_*.png`)
- Distribution plots (`distribution_*.png`)
- ROC curves (`roc_*.png`)
- Precision-Recall curves (`pr_curve_*.png`)

## Requirements

- PyTorch
- Transformers
- Datasets
- NumPy
- Matplotlib
- Seaborn
- scikit-learn
- tqdm

## Usage

Run the Jupyter notebook [fast_detect_gpt.ipynb](fast_detect_gpt.ipynb) to:
1. Download and prepare the datasets
2. Generate text samples using GPT-2
3. Run the Fast-DetectGPT detection algorithm
4. Evaluate performance and generate visualizations

If you have issues viewing the notebook, you can access a rendered version here:
[View notebook on nbviewer](https://nbviewer.org/github/laurentlaurent/LLM-generated-text-detection/blob/main/fast_detect_gpt_with_output.ipynb)